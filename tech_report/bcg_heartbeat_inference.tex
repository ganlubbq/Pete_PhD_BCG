\documentclass{article}

%%% Packages %%%

% Graphics
\usepackage{graphicx}
\usepackage[caption=false,font=footnotesize]{subfig}

% Formatting
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage[T1]{fontenc}

% Environments
\usepackage{IEEEtrantools}
\usepackage{algorithm}
\usepackage{algorithmic}

% References
\usepackage{natbib}

% Macro
\usepackage{etoolbox}


%%% Graphics %%%
\graphicspath{{figures/}}


%%% Macros %%%
\input{bcg_heartbeat_inference_macros}


%%% Environments %%%
\newenvironment{meta}[0]{\color{red} \em}{}
\newtheorem{lemma}{Lemma}


%%% Titles and stuff %%%
\title{Variable Rate Algorithms for Inference of Heartbeats in a Balistocardiography Signal}
\author{Pete Bunch}


%%% DOCUMENT %%%
\begin{document}

\maketitle

\section{Introduction}



\section{Variable Rate Models}

In contrast with a standard hidden Markov model, the dynamics of the latent state in a variable rate model are dependent of a series of changepoints which occur at instantaneous moments in continuous time, and their associated parameters.

Consider a time interval $[0,\ctmax]$ during which observations $\{\ob{1} \dots \ob{\timax}\}$ are made at times $\{\ot{1} \dots \ot{\timax}\}$ (where for convenience we require $\ot{1}=0$ and $\ot{\timax}=\ctmax$). During this period an unknown number of changepoints $\fcpi$ occur at times $\{\cpt{1} \dots \cpt{\fcpi} \}$, each with associated changepoint parameters $\{\cpp{1} \dots \cpp{\fcpi} \}$. (Furthermore, $\cpt{0}$ and $\cpp{0}$ are the changepoint time and parameter immediately preceding the beginning of the observations.) Henceforth, discrete sets such as these will be written in the format $z_{1:\ti} = \{z_{1} \dots z_{\ti}\}$.

Inference algorithms for variable rate models will require us to manipulate and calculate probabilities for sequences of changepoints. To this end, we also define the following variable for the sequence of changepoint times and parameters up until a particular observation instant,
%
\begin{IEEEeqnarray}{rCl}
 \cp{\ti} = \{\cpt{j}, \cpp{j} \: \forall j : 0 < \cpt{j+1}, \cpt{j} < \ot{\ti} \} \nonumber      ,
\end{IEEEeqnarray}
%
and likewise for between two of the observation instants,
%
\begin{IEEEeqnarray}{rCl}
 \cp[\ti_1]{\ti_2} = \{\cpt{j}, \cpp{j} \: \forall j : \ot{\ti_1} \leq \cpt{j} < \ot{\ti_2} \} \nonumber      .
\end{IEEEeqnarray}

A final piece of notation, the following counting variables are introduced to keep track of the most recent changepoint to have occurred,
%
\begin{IEEEeqnarray}{rCl}
 \mrcpi(\ct)  & = & \max(\cpi : \cpt{\cpi}<\ct) \nonumber \\
 \mrcpi_{\ti} & = & \mrcpi(\ot{\ti}) \nonumber      .
\end{IEEEeqnarray}

The times and parameters of the changepoints are distributed as,
%
\begin{IEEEeqnarray}{rCl}
 \left\{ \cpt{\cpi}, \cpp{\cpi} \right\} & \sim & \cptransden{\cpt{},\cpp{}}(\cpt{\cpi}, \cpp{\cpi} | \cpt{0:\cpi-1}, \cpp{0:\cpi-1}) \nonumber      ,
\end{IEEEeqnarray}
%
with this distribution constructed such that $\prob(\cpt{\cpi} < \cpt{\cpi-1}) = 0$. Just as in \citep{Whiteley2011}, a survivor function is defined for the probability that no new changepoint occurs before a given time,
%
\begin{IEEEeqnarray}{rCl}
 \survfunc{\cpt{0:\cpi}}{\cpp{0:\cpi}}{\ct} & = & \prob(\cpt{\cpi+1} > \ct | \cpt{0:\cpi}, \cpp{0:\cpi}) \nonumber \\
 & = & 1 - \int_{\cpt{\cpi}}^{\ct} \cptransden{\cpt{}}(\xi | \cpt{0:\cpi}, \cpp{0:\cpi}) \nonumber      .
\end{IEEEeqnarray}

Each changepoint sequence $\cp[\ti_1]{\ti_2}$ constitutes a finite duration marked point process, taking values in the space formed by the disjoint union,
%
\begin{IEEEeqnarray}{rCl}
 \cpspace[\ti_1]{\ti_2} & = & \bigcup_l \{l\} \times \cptspace[\ti_1]{\ti_2,l} \times \cppspace^l \nonumber      ,
\end{IEEEeqnarray}
%
where $\cppspace$ is the space of $\cpp{\cpi}$ and $\cptspace[\ti_1]{\ti_2,l} \subset \reals^l$ is the space spanned by $l$ changepoint times subject to the conditions that they all lie in the interval $[\ot{\ti_1},\ot{\ti_2}]$ and that each is greater than its predecessor.

A rigorous treatment of probability distributions over marked point processes may be found in \citep{Jacobsen2006}. We can write the following prior distribution for a changepoint sequence,
%
\begin{IEEEeqnarray}{rCl}
 \cptransden{\cp{}}(\cp{\ti}) & = & \survfunc{\cpt{0:\mrcpi_{\ti}}}{\cpp{0:\mrcpi_{\ti}}}{\ot{\ti}} \cptransden{\cpt{},\cpp{}}(\cpt{0},\cpp{0}) \prod_{\cpi=1}^{\mrcpi_{\ti}} \cptransden{\cpt{},\cpp{}}(\cpt{\cpi}, \cpp{\cpi} | \cpt{0:\cpi-1}, \cpp{0:\cpi-1}) \nonumber      ,
\end{IEEEeqnarray}
%
and hence the sequence transition density is,
%
\begin{IEEEeqnarray}{rCl}
 \cptransden{\cp{}}(\cp[\ti_1]{\ti_2} | \cp{\ti_1}) & = & \frac{ \cptransden{\cp{}}(\cp{\ti_2}) }{ \cptransden{\cp{}}(\cp{\ti_1}) } \nonumber \\
 & = & \frac{ \survfunc{\cpt{0:\mrcpi_{\ti_2}}}{\cpp{0:\mrcpi_{\ti_2}}}{\ot{\ti_2}} }{ \survfunc{\cpt{0:\mrcpi_{\ti_1}}}{\cpp{0:\mrcpi_{\ti_1}}}{\ot{\ti_1}} } \prod_{\cpi=\mrcpi_{\ti_1}+1}^{\mrcpi_{\ti_2}} \cptransden{\cpt{},\cpp{}}(\cpt{\cpi}, \cpp{\cpi} | \cpt{0:\cpi-1}, \cpp{0:\cpi-1}) \nonumber      .
\end{IEEEeqnarray}



\subsection{State Dynamics and Observation Likelihoods}

The latent state is a continuous-time process denoted $\cls{\ct} \in \lsspace$ which evolves according to some benign dynamics conditional upon the changepoint sequence. In this paper we consider only one of several possible classes of state dynamics which encompasses the various balistocardiography models introduced.

In our BCG models, the latent state evolution is governed by the changepoint sequence alongside an additional set of auxiliary variables. There will be one auxiliary variable $\cplp{\cpi}$ corresponding to each changepoint time $\cpt{\cpi}$. This new variable is distinguished from the existing changepoint parameter by the fact that it evolves according to a linear Gauss-Markov model,
%
\begin{IEEEeqnarray}{rCl}
 \cptransden{\cplp{}}(\cplp{\cpi} | \cpt{0:\cpi}, \cpp{0:\cpi}, \cplp{0:\cpi-1}) & = & \normalden{\cplp{\cpi}}{\cplptransmat \cplp{\cpi}}{\cplptranscov} \nonumber \\
  \cptransden{\cplp{}}(\cplp{0}) & = & \normalden{\cplp{\cpi}}{\cplpmn{0}}{\cplpvr{0}} \nonumber      ,
\end{IEEEeqnarray}

Conditional upon the changepoint sequence, the state is a deterministic linear function of the most recent auxiliary variable,
%
\begin{IEEEeqnarray}{rCl}
 \cls{\ct} & = & \transfun(\ct) \cplp{\mrcpi(\ct)} \nonumber      .
\end{IEEEeqnarray}

Finally, the dependence of the observations on the latent state is also linear and Gaussian,
%
\begin{IEEEeqnarray}{rCl}
 \lhood(\ob{\ti} | \cls{\ot{\ti}}) & = & \normalden{\ob{\ti}}{\obsmat \cls{\ot{\ti}}}{\obscov} \nonumber      .
\end{IEEEeqnarray}

The matrixes $\obsmat$, $\obscov$, $\cplptransmat$, $\cplptranscov$ may all be functions of $\cpt{0:\mrcpi_{\ti}}, \cpp{0:\mrcpi_{\ti}}$, and $\transfun(\ct)$ may be a function of $\cpt{0:\mrcpi(\ct)}, \cpp{0:\mrcpi(\ct)}$, but this is suppressed above for clarity.

Variable rate models with a similar structure were studied in \citep{Morelande2009a}.








%The state is modelled as a evolving deterministically conditional upon the changepoint sequence and an additional linear changepoint parameter
%
% the state dynamical models which we study are conditionally deterministic, i.e. the state is precisely determined by the sequence of changepoints and a starting point, $\cls{\cpt{0}}=\ls{0}$, with no additional random components. A state transition function may then be written,
%%
%\begin{IEEEeqnarray}{rCl}
% \cls{\ct} & = & \transfun\left( \ls{0}, \cpt{0:\mrcpi(\ct)}, \cpp{0:\mrcpi(\ct)}, \ct \right) \nonumber      .
%\end{IEEEeqnarray}
%
%To complete the model, we define a likelihood density for each observation conditional upon the latent state at that time,
%%
%\begin{IEEEeqnarray}{c}
% \lhood(\ob{\ti} | \cls{\ot{\ti}}) \nonumber       .
%\end{IEEEeqnarray}
%
%In this case, the likelihood of an observation given the changepoint sequence may be written as,
%%
%\begin{IEEEeqnarray}{rCl}
% \lhood(\ob{\ti} | \cp{\ti}) & = & \lhood(\ob{\ti} | \cls{\ot{\ti}}) \nonumber       .
%\end{IEEEeqnarray}
%
%\subsection{Rao-Blackwellising the Parameters}
%
%A further elaboration to the basic variable rate model is now explored. We divide each changepoint parameter into two parts $\{\cpp{\cpi}, \cplp{\cpi}\}$, the latter of which evolves according linear Gauss-Markov dynamics conditional upon the rest of the sequence,
%%
%\begin{IEEEeqnarray}{rCl}
% \left\{ \cpt{\cpi}, \cpp{\cpi}, \cplp{\cpi} \right\} & \sim & \cptransden{\cpt{},\cpp{}}(\cpt{\cpi}, \cpp{\cpi} | \cpt{0:\cpi-1}, \cpp{0:\cpi-1}) \cptransden{\cplp{}}(\cplp{\cpi} | \cpt{0:\cpi}, \cpp{0:\cpi})\nonumber \\
% \cptransden{\cplp{}}(\cplp{\cpi} | \cpt{0:\cpi}, \cpp{0:\cpi}) & = & \normalden{}{}{} \nonumber      .
%\end{IEEEeqnarray}
%
%Assume also, that the observation density is linear and Gaussian,
%%
%\begin{IEEEeqnarray}{rCl}
% \lhood(\ob{\ti} | \cls{\ot{\ti}}) & = & \normalden{\ob{\ti}}{\obsmat \cls{\ot{\ti}}}{\obscov}
%\end{IEEEeqnarray}
%%
%then the linear parameters may be analytically marginalised, a process known as Rao-Blackwelliation. A filter employing this strategy is detailed in \citep{Morelande2009a}.
%
%With such a model structure, the likelihood of an observation given the changepoint sequence and previous observations may be written as,
%%
%\begin{IEEEeqnarray}{rCl}
% \lhood(\ob{\ti} | \cp{\ti}) & = & \int \normalden{\ob{\ti}}{\obsmat \cls{\ot{\ti}}}{\obscov}
% \lhood(\ob{\ti} | \cls{\ot{\ti}}) \nonumber       .
%\end{IEEEeqnarray}




\section{Variable Rate Block Filtering}

The analytic calculation of posterior distributions over the changepoint sequence is generally intractable. Instead, we resort to particle algorithms, in which each distribution is represented by a set of weighted particles sampled from it,
%
\begin{IEEEeqnarray}{rCl}
 p(\cp{\ti} | \ob{1:\ti}) & \approx & \sum_j \pw{\ti}\pss{j} \delta_{ \cp{\ti}\pss{j} }(\cp{\ti}) \nonumber      .
\end{IEEEeqnarray}
%
The state dynamical model is constructed so that $p(\cls{\ct}|\cp{\ti}, \ob{1:\ti})$ may be calculated analytically (for $\ct<\ot{\ti}$) --- this conditional posterior is commonly deterministic or Gaussian --- and hence the following approximation to the latent state distribution is made,
%
\begin{IEEEeqnarray}{rCll}
 p(\cls{\ct} | \ob{1:\ti}) & = & \int p(\cls{\ct}|\cp{\ti}\pss{j}, \ob{1:\ti}) p(\cp{\ti} | \ob{1:\ti}) d\cp{\ti} &, \qquad \ct < \ot{\ti} \nonumber \\
 & \approx & \sum_j \pw{\ti}\pss{j} p(\cls{\ct}|\cp{\ti}\pss{j}, \ob{1:\ti}) \nonumber      .
\end{IEEEeqnarray}

\subsection{Motivation}

The principal difficulty in devising inference algorithms for variable rate models is that changepoints are rarely apparent from the observations until a significant time after they have occurred. For example, when tracking a manoeuvering vehicle from measurements of its position, an abrupt change in its acceleration will not be evident until a sufficient deviation in course from its previous motion has accumulated. This phenomenon results in simpler particle filters, which at each time step extend the changepoint sequence from $\ot{\ti}$ to $\ot{\ti+1}$ in a straightforward manner \citep{Godsill2004a,Godsill2007}, to be quite ineffective in many cases. Performance may be substantially improved by allowing retrospective alterations to the changepoint sequence. This was achieved by \citet{Bunch2013} by including resample-move steps \citep{Gilks2001}, and by \citet{Whiteley2011} with the use of an SMC sampler \citep{DelMoral2006,Doucet2006}.

The obvious disadvantage of allowing retrospective alterations to the changepoint sequence is that the computational burden of the algorithm is substantially increased. With no restrictions on the permitted alterations, the complexity becomes $\bigo{\timax^2}$. By imposing a maximum window length spanning $\winlen$ observations, this may be reduced to $\bigo{\timax \times \winlen}$, but this may still be prohibitive. Here we propose an algorithm which abandons the requirement for the filter to update with the arrival of every new observation, but only once for each block of $\blocklen$. This reduces the complexity to $\bigo{\frac{\timax \times \winlen}{\blocklen}}$. The block length $\blocklen$ will be smaller than the window length $\winlen$ by a small factor (say $1.5$--$3$) meaning that there is still significant overlap between the windows of subsequent processing steps. Changepoints which occur late in the window at one processing step will be earlier in the window at the next step, and estimates may be revised in the light of the new observations received.

Apart from updating only once per block, the particle filter proposed here bears many similarities with the algorithm of \citet{Whiteley2011} but also the following important difference. We formulate proposals in terms of the changepoint sequence $\cp[\ot{\ti_1}]{\ot{\ti_2}}$, rather than by explicitly adjusting, adding or removing individual changepoints. Ultimately, these two systems can be seen as equivalent, but we find our framework better adapted to the types of proposals we wish to use. In particular, alterations to the number of changepoints in the window are more easily handled.

\subsection{Formulation}

In a particular processing step, the block particle filter targets the distribution $p(\cp{\ti+\winlen} | \ob{1:\ti+\winlen})$. A set of (weighted) particles is available from the previous processing step which approximate $p(\cp{\ti-\blocklen+\winlen} | \ob{1:\ti-\blocklen+\winlen})$. For the $(i)$th particle, the proposal begins by selecting one of those from the previous set with probability proportional to its weight (i.e. a resampling step), so that roughly,
%
\begin{IEEEeqnarray}{rCl}
 \cp{\ti-\blocklen+\winlen}\pss{i} & \sim & p(\cp{\ti-\blocklen+\winlen} | \ob{1:\ti-\blocklen+\winlen}) \nonumber      .
\end{IEEEeqnarray}
%
A new value is then sampled for the changepoint sequence between $\ot{\ti}$ and $\ot{\ti+\winlen}$ from an importance distribution,
%
\begin{IEEEeqnarray}{rCl}
 \repcp[\ti]{\ti+\winlen}\pss{i} & \sim & \impden{\ti}{\ti+\winlen}(\cp[\ti]{\ti+\winlen} | \cp{\ti-\blocklen+\winlen}\pss{i}) \nonumber      .
\end{IEEEeqnarray}

In order to avoid an intractable integral over the discarded changepoint sequence overlap, the target distribution is extended with an artificial conditional distribution, using the method introduced in \citep{DelMoral2006,Doucet2006},
%
\begin{IEEEeqnarray}{rCl}
 p(\cp{\ti}, \repcp[\ti]{\ti+\winlen} | \ob{1:\ti+\winlen}) \artden{\ti}{\ti-\blocklen+\winlen}( \cp[\ti]{\ti-\blocklen+\winlen} | \cp{\ti}, \repcp[\ti]{\ti+\winlen}) \nonumber      .
\end{IEEEeqnarray}

The resulting importance weight is given by the ratio,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\ti}\pss{i} & = & \frac{ p(\cp{\ti}\pss{i}, \repcp[\ti]{\ti+\winlen}\pss{i} | \ob{1:\ti+\winlen}) \artden{\ti}{\ti-\blocklen+\winlen}( \cp[\ti]{\ti-\blocklen+\winlen}\pss{i} | \cp{\ti}\pss{i}, \repcp[\ti]{\ti+\winlen}\pss{i}) }{ p(\cp{\ti-\blocklen+\winlen}\pss{i} | \ob{1:\ti-\blocklen+\winlen}) \impden{\ti}{\ti+\winlen}(\repcp[\ti]{\ti+\winlen}\pss{i} | \cp{\ti-\blocklen+\winlen}\pss{i}) } \nonumber        ,
\end{IEEEeqnarray}
%
Having completed the importance sampling, the overlapping portion of each old sequence $\cp[\ti]{\ti-\blocklen+\winlen}\pss{i}$ is discarded, and the final particle is constructed,
%
\begin{IEEEeqnarray}{rCl}
 \cp{\ti+\winlen}\pss{i} \leftarrow \left\{ \cp{\ti}\pss{i}, \cp[\ti]{\ti+\winlen}\pss{i} \right\} \nonumber       .
\end{IEEEeqnarray}

A valid algorithm results whatever choice is made for $\artden{\ti}{\ti-\blocklen+\winlen}$, but some will lead to desirable lower variances of the importance weights. 

\subsection{Evaluating the Likelihood}

For our particular auxiliary variable, conditionally-deterministic state dynamics, the model for the auxiliary variables is linear-Gaussian and Markovian when conditioned on the changepoint sequence. The conditional posterior distribution is thus Gaussian, and the parameters may be calculated analytically with a Kalman filter,
%
\begin{IEEEeqnarray}{rCl}
 p(\cplp{\mrcpi{\ti}} | \cp{\ti}, \ob{1:\ti}) & = & \normalden{\cplp{\mrcpi{\ti}}}{\cplpmn{\ti}}{\cplpvr{\ti}} \nonumber \\
 p(\cplp{\mrcpi{\ti}} | \cp{\ti}, \ob{1:\ti-1}) & = & \normalden{\cplp{\mrcpi{\ti}}}{\cplppredmn{\ti}}{\cplppredvr{\ti}} \nonumber      .
\end{IEEEeqnarray}
%
When progressing the Kalman filter from $\ot{\ti}$ to $\ot{\ti+1}$, a variable number of prediction steps occur, one for each changepoint present in the interval (which, in practice, will be either $0$ or $1$).

Using the Kalman filter moments, the marginal likelihood term required for the particle filter weight evaluation is given by,
%
\begin{IEEEeqnarray}{rCl}
 \lhood(\ob{\ti+1:\ti+\winlen} | \cp{\ti+\winlen}, \ob{1:\ti}) & = & \prod_l \lhood(\ob{\ti+l} | \cp{\ti+\winlen}, \ob{1:\ti+l-1}) \nonumber \\
 \lhood(\ob{\ti+l} | \cp{\ti+\winlen}, \ob{1:\ti+l-1}) & = & \int \lhood(\ob{\ti+l} | \cp{\ti+\winlen}, \cplp{\mrcpi{\ti+l}}) \lhood(\cplp{\mrcpi{\ti+l}} | \cp{\ti+\winlen}, \ob{1:\ti+l-1}) d\cplp{\mrcpi{\ti+l}} \nonumber \\
 & = & \normalden{\ob{\ti+l}}{ \obsmat \transfun \cplppredmn{\ti+l} }{ \obsmat \transfun \cplppredvr{\ti+l} \transfun ^T\obsmat^T + \obscov } \nonumber      .
\end{IEEEeqnarray}



\subsection{Importance and Extension Distributions}

Although far from optimal, our first experiments will use the simplest options for both the importance and extension distributions, the transition densities for the respective sequences,
%
\begin{IEEEeqnarray}{rCl}
 \impden{\ti}{\ti+\winlen}(\repcp[\ti]{\ti+\winlen} | \cp{\ti-\blocklen+\winlen}) & = & \cptransden{\cp{}}(\repcp[\ti]{\ti+\winlen} | \cp{\ti}) \nonumber \\
 \artden{\ti}{\ti-\blocklen+\winlen}( \cp[\ti]{\ti-\blocklen+\winlen} | \cp{\ti}, \repcp[\ti]{\ti+\winlen}) & = & \cptransden{\cp{}}(\cp[\ti]{\ti-\blocklen+\winlen} | \cp{\ti}) \nonumber      .
\end{IEEEeqnarray}
%
With these choices we have,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\ti}\pss{i} & \propto & \frac{ \lhood(\ob{\ti+1:\ti+\winlen} | \cp{\ti}\pss{i}, \repcp[\ti]{\ti+\winlen}\pss{i}, \ob{1:\ti}) }{ \lhood(\ob{\ti+1:\ti-\blocklen+\winlen} | \cp{\ti-\blocklen+\winlen}\pss{i}, \ob{1:\ti}) } \nonumber       .
\end{IEEEeqnarray}

An improved proposal method tailored to the heartbeat models is discussed in section~\ref{}{\meta Add ref.}



\section{Variable Rate Models for Balistocardiography}

\subsection{System Outline}

The balistocardiography (BCG) system under consideration consists of four force sensors placed under the legs of a bed, which are capable of recording the vibration caused by the subject's beating heart. Robust detection of the heartbeats in this signal is, however, a challenging problem. The heartbeat waveforms reaching the sensors exhibit significant variation depending on the bed, the subject, the position in which they lie, and many other factors. Moreover, these waveforms do not often possess a clear principal peak from which beat timings may be extracted, as an electrocardiography (ECG) signal often does. In addition, the signal is corrupted by frequent interference arising from the subject moving. Finally, the task becomes much more difficult when there are two people lying in the bed together. The sensors now measure a combination of two heartbeat signals which must be separated in parallel as the timings are inferred. The BCG inference task fits naturally into the variable rate framework, which heartbeat times corresponding to changepoints.

{\meta Add some examples.}

\subsection{Preprocessing}

The measurements from the four sensors are first low-pass filtered with a cut-off frequency of $15Hz$, and then down-sampled to $30Hz$. Another filter is used to remove the D.C. bias.

\subsection{The Basic Model}

We first consider a simple case: one person in the bed and no disturbances.

The start time of the $(\cpi)$th beat is denoted $\hbst{\cpi}$. The start of the next beat is assumed to have a shifted gamma distribution with some variable minimum beat duration $\hbmd{\cpi}$. The minimum beat duration is also modelled as gamma distributed with a mean equal to the value from the previous beat. Hence,
%
\begin{IEEEeqnarray}{rCl}
 \cptransden{\hbst{},\hbmd{}}( \hbst{\cpi+1}, \hbmd{\cpi+1} | \hbst{\cpi}, \hbmd{\cpi} ) & = & \gammaden{\hbst{\cpi+1}-\hbst{\cpi}-\hbmd{\cpi}}{\gamshape{\hbst{}}}{\gamscale{\hbst{}}} \gammaden{\hbmd{\cpi+1}}{\frac{\hbmd{\cpi}}{\gamscale{\hbmd{}}}}{\gamscale{\hbmd{}}} \nonumber      ,
\end{IEEEeqnarray}
%
where $\gammaden{x}{a}{b}$ represents a gamma density for $x$ with shape and scale parameters $a$ and $b$ respectively. $\gamshape{\hbst{}}$, $\gamscale{\hbst{}}$ and $\gamscale{\hbmd{}}$ are fixed parameters.

The latent state is a four-dimensional quantity representing the noise-free vibration signal reaching each of the four sensors. Associated with each heartbeat and each sensor we introduce a waveform template variable $\hbwf{\si,\cpi}$. This is a vector of points parameterising the continuous-time waveform. If the waveform were known a priori, the discrete template could be obtained by sampling it at the same rate as the observations. The signal at some arbitrary time during the beat $\hbst{\cpi} < t \leq \hbst{\cpi+1}$ is then specified deterministically by linear basis-function interpolation between these points,
%
\begin{IEEEeqnarray}{rCl}
 \hs{\si}{\ct} & = & \intrp(\hbst{\mrcpi(\ct)},\ct) \cdot \hbwf{\si,\mrcpi(\ct)} \nonumber      ,
\end{IEEEeqnarray}
%
where $\hs{\si}{\ct}$ is the $(\si)$th component of $\hs{}{\ct}$, and $\intrp(\hbst{\cpi},\ct)$ is a vector of interpolation factors. For example, using sinc interpolation,
%
\begin{IEEEeqnarray}{rCl}
 \intrp_{i}(\hbst{\cpi},\ct) & = & \sinc\left( \frac{\ct-\hbst{\cpi}- i \period}{\period} \right) \nonumber     ,
\end{IEEEeqnarray}
%
where $\period$ is the sampling period and $\hbwflen$ is the length of $\hbwf{\si,\cpi}$. Concatenating the state components, we have,
%
\begin{IEEEeqnarray}{rCl}
 \hs{}{\ct} & = & \underbrace{\begin{bmatrix} \intrp(\hbst{\mrcpi(\ct)},\ct)^T & 0 & 0 & 0 \\ 0 & \intrp(\hbst{\mrcpi(\ct)},\ct)^T & 0 & 0 \\ 0 & 0 & \intrp(\hbst{\mrcpi(\ct)},\ct)^T & 0 \\ 0 & 0 & 0 & \intrp(\hbst{\mrcpi(\ct)},\ct)^T \end{bmatrix}}_{ \intrpmat\left(\hbst{\mrcpi(\ct)},\ct\right) } \underbrace{\begin{bmatrix} \hbwf{1,\mrcpi(\ct)} \\ \hbwf{2,\mrcpi(\ct)} \\ \hbwf{3,\mrcpi(\ct)} \\ \hbwf{4,\mrcpi(\ct)} \end{bmatrix}}_{\hbwf{\mrcpi(\ct)}} \nonumber      .
\end{IEEEeqnarray}

Measurements are denoted $\ob{\ti}$ (as in the general framework) and are modelled as noisy observations of the heartbeat signal,
%
\begin{IEEEeqnarray}{rCl}
 \lhood(\ob{\ti} | \hs{}{\ot{\ti}}) & = & \normalden{\ob{\ti}}{\hs{}{\ot{\ti}}}{\hbobscov} \nonumber      .
\end{IEEEeqnarray}

Finally, heartbeat waveform templates are modelled as a Markovian sequence with Gaussian prior and transition densities.
%
\begin{IEEEeqnarray}{rCl}
 p(\hbwf{\si,0}) & = & \normalden{\hbwf{\si,0}}{0}{\hbwfpriorcov} \nonumber \\
 p(\hbwf{\si,\cpi} | \hbwf{\si,\cpi-1}) & = & \normalden{\hbwf{\si,\cpi}}{\hbwf{\si,\cpi-1}}{\hbwftranscov} \nonumber      .
\end{IEEEeqnarray}
%
The prior covariance matrix $\hbwfpriorcov$ is chosen to be diagonal, with very small values at the ends and a larger value in the middle. This reflects our expectation that the waveform should have the greatest amplitude roughly in the middle of the beat. Specifically, we use,
%
\begin{IEEEeqnarray}{rCl}
 \hbwfpriorcov_{i,i} & = & \sigma_{\omega}^2 \times \half \left( 1-\cos\left( \frac{ 2 \pi i }{ \hbwflen+1 } \right) \right)^2 \nonumber      .
\end{IEEEeqnarray}
%
The transition covariance matrix $\hbwftranscov$ is the identity multiplied by a small positive constant.

This model fits exactly into the framework laid out in section~\ref{}{\meta Add ref.}, with the following correspondence,
%
\begin{IEEEeqnarray}{rCl}
 \cpt{\cpi} & = & \hbst{\cpi} \nonumber \\
 \cpp{\cpi} & = & \hbmd{\cpi} \nonumber \\
 \cplp{\cpi} & = & \hbwf{\cpi} \nonumber \\
 \cls{\ct} & = & \hs{}{\ct} \nonumber       .
\end{IEEEeqnarray}



\subsection{Variations on the Basic Model}

\subsubsection{Simplifying Waveform Template Estimation}

If only a short section of data is to be studied, then it may be valid to assume that the waveform template is constant for every beat. In this case, it is only necessary to specify a prior,
%
\begin{IEEEeqnarray}{rCl}
 p(\hbwf{\si}) & = & \normalden{\hbwf{\si}}{0}{\hbwfpriorcov} \nonumber       .
\end{IEEEeqnarray}
%
The algorithm proceeds as before except that all Kalman filter prediction steps are omitted when calculating the waveform template conditional posterior distributions. With this modification, we now have,
%
\begin{IEEEeqnarray}{rCl}
 \cplp{\cpi} & = & \hbwf{} \nonumber      .
\end{IEEEeqnarray}

\subsubsection{A Smoother Likelihood Function}

As formulated, the observation density for the $(\ti)$th observation is not a smooth function of the changepoint sequence; it contains a jump at the point $\ot{\ti}=\cpt{\mrcpi{\ti}}$, as the observation is shifted from one heartbeat to the next. This is problematic for gradient ascent algorithms seeking a peak in the likelihood function. To alleviate this problem, we use a window function to smoothly taper between the heartbeats,
%
\begin{IEEEeqnarray}{rCl}
 \hs{\si}{\ct} & = & \begin{cases} \left[1-\window\left(\frac{\ct-\cpt{\mrcpi(\ct)}}{\period}\right)\right] \intrp(\hbst{\mrcpi(\ct)-1},\ct) \cdot \hbwf{\si,\mrcpi(\ct)-1} & \\
 \qquad  + \window\left(\frac{\ct-\cpt{\mrcpi(\ct)}}{\period}\right) \intrp(\hbst{\mrcpi(\ct)},\ct) \cdot \hbwf{\si,\mrcpi(\ct)} & \cpt{\mrcpi(\ct)} < \ct \leq \cpt{\mrcpi(\ct)} + \period \\
 \intrp(\hbst{\mrcpi(\ct)},\ct) \cdot \hbwf{\si,\mrcpi(\ct)} & \cpt{\mrcpi(\ct)} + \period < \ct < \cpt{\mrcpi(\ct)+1}
 \end{cases} \nonumber      ,
\end{IEEEeqnarray}
%
where $\window(\ct)$ is a monotonically non-decreasing function with $\window(0)=0$ and $\window(1)=1$ and with zero gradient at both $\ct=0$ and $\ct=1$. For example,
%
\begin{IEEEeqnarray}{rCl}
 \window(t) & = & \half\left[1 - \cos(\pi t)\right] \nonumber      .
\end{IEEEeqnarray}

Because of the overlap between the heartbeats, the latent state may now depend on the preceding two heartbeat waveforms. Therefore, in order for this model to adhere to the framework set out in section~\ref{}{\meta Add ref.}, we now use,
%
\begin{IEEEeqnarray}{rCl}
 \cplp{\cpi} & = & \begin{bmatrix} \hbwf{\cpi} \\ \hbwf{\cpi-1} \end{bmatrix} \nonumber      ,
\end{IEEEeqnarray}
%
along with the obvious augmentation of the interpolation matrix $\transfun$.



\subsection{Modelling Heartbeat Combinations}

When there are two people sleeping in the bed, the heartbeat signals are treated as independent a priori. (An interesting question is whether this assumption is valid --- will heartbeat rhythms ever ``sync up''?) Thus, we have two sequences of heartbeat start times, minimum durations and waveform templates,
%
\begin{IEEEeqnarray}{rCl}
 \left\{ \hbst[\peri]{\cpi}, \hbmd[\peri]{\cpi}, \hbwf[\peri]{\cpi} \right\} \: \peri=1,2 \nonumber      ,
\end{IEEEeqnarray}
%
and also two noise-free heartbeat signals $\hs[\peri]{}{\ct} \: \peri=1,2$ each determined by its respective sequence by \eqref{} or \eqref{}{\meta Add refs}. The measurements are modelled as noisy observations of the sum of these signals. Thus, we now have,
%
\begin{IEEEeqnarray}{rClCrCl}
 \cpt{\cpi} & = & \begin{bmatrix} \hbst[1]{\cpi} \\ \hbst[2]{\cpi} \end{bmatrix} & \qquad & \cpp{\cpi} & = & \begin{bmatrix} \hbmd[1]{\cpi} \\ \hbmd[2]{\cpi} \end{bmatrix} \nonumber \\
  \nonumber \\
 \cplp{\cpi} & = & \begin{bmatrix} \hbwf[1]{\cpi} \\ \hbwf[2]{\cpi} \end{bmatrix} & \qquad & \cls{\ct} & = & \hs[1]{}{\ct} + \hs[2]{}{\ct} \nonumber       .
\end{IEEEeqnarray}




\subsection{Modelling Clutter and Interference}

\subsection{Sampling Changepoint Sequences}

For the heartbeat inference problem investigated in this paper a simple but effective modification to this basic proposal is possible. Because the observations are highly informative (high dimension and low noise), it is vital to propose heartbeat sequences close to peaks in the likelihood. {\meta Graph.}



\subsection{Initialising the Algorithm}




\section{Implementation and Testing}


\bibliographystyle{dcu}
\bibliography{D:/pb404/Dropbox/PhD/Cleanbib}
\end{document} 